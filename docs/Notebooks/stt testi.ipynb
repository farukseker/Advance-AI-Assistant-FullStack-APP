{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f957a6be-7f37-47af-b9ce-26f01a8ad457",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T07:51:07.742692Z",
     "iopub.status.busy": "2026-02-04T07:51:07.742456Z",
     "iopub.status.idle": "2026-02-04T07:51:07.761665Z",
     "shell.execute_reply": "2026-02-04T07:51:07.761018Z",
     "shell.execute_reply.started": "2026-02-04T07:51:07.742674Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6670ecc-9405-4639-8744-14230d8f229f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T08:12:12.311843Z",
     "iopub.status.busy": "2026-02-04T08:12:12.311571Z",
     "iopub.status.idle": "2026-02-04T08:12:12.314451Z",
     "shell.execute_reply": "2026-02-04T08:12:12.313835Z",
     "shell.execute_reply.started": "2026-02-04T08:12:12.311829Z"
    }
   },
   "outputs": [],
   "source": [
    "OPENROUTER_API_KEY = config.get('OPENROUTER_API_KEY')\n",
    "OPENROUTER_API_HOST = config.get('OPENROUTER_API_HOST')\n",
    "STT_MODEL=\"openai/gpt-audio-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66afea09-4b25-4fef-a3ec-e316c1fdefc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T08:12:12.686555Z",
     "iopub.status.busy": "2026-02-04T08:12:12.686381Z",
     "iopub.status.idle": "2026-02-04T08:12:12.689882Z",
     "shell.execute_reply": "2026-02-04T08:12:12.689122Z",
     "shell.execute_reply.started": "2026-02-04T08:12:12.686541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://openrouter.ai/api/v1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPENROUTER_API_HOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a2e9822-6b2e-4cba-87ea-274abc26c523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T08:15:02.114576Z",
     "iopub.status.busy": "2026-02-04T08:15:02.114345Z",
     "iopub.status.idle": "2026-02-04T08:15:06.674163Z",
     "shell.execute_reply": "2026-02-04T08:15:06.673555Z",
     "shell.execute_reply.started": "2026-02-04T08:15:02.114563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Hey there! I'm doing well, thanks for asking. How about you?\n",
      "\n",
      "Audio saved to output.wav (204000 bytes)\n",
      "Processing...\n",
      "Thanks for the test message! Everything seems to be working fine. Let me know if there's anything specific you'd like to talk about!\n",
      "\n",
      "Audio saved to test.wav (328800 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test.wav'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import wave\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=STT_MODEL,\n",
    "    modalities=[\"text\", \"audio\"],\n",
    "    stream=True,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Repat with your voice what user sayings\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello, how are you?\"\n",
    "        }\n",
    "    ],\n",
    "    audio={\n",
    "        \"voice\": \"alloy\",\n",
    "        \"format\": \"pcm16\"\n",
    "    }\n",
    ")\n",
    "\n",
    "text_response = \"\"\n",
    "audio_chunks = []\n",
    "transcript = \"\"\n",
    "audio_id = None\n",
    "\n",
    "print(\"Streaming response...\\n\")\n",
    "\n",
    "for chunk in response:\n",
    "    # Collect text content\n",
    "    if chunk.choices[0].delta.content:\n",
    "        text_content = chunk.choices[0].delta.content\n",
    "        text_response += text_content\n",
    "        print(text_content, end=\"\", flush=True)\n",
    "    \n",
    "    # Collect audio data and transcript\n",
    "    if hasattr(chunk.choices[0].delta, 'audio') and chunk.choices[0].delta.audio:\n",
    "        audio_dict = chunk.choices[0].delta.audio\n",
    "        \n",
    "        # audio_dict is a dictionary\n",
    "        if isinstance(audio_dict, dict):\n",
    "            # Get audio ID\n",
    "            if 'id' in audio_dict and audio_dict['id']:\n",
    "                audio_id = audio_dict['id']\n",
    "            \n",
    "            # Get audio data\n",
    "            if 'data' in audio_dict and audio_dict['data']:\n",
    "                try:\n",
    "                    decoded_audio = base64.b64decode(audio_dict['data'])\n",
    "                    audio_chunks.append(decoded_audio)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError decoding audio: {e}\")\n",
    "            \n",
    "            # Get transcript\n",
    "            if 'transcript' in audio_dict and audio_dict['transcript']:\n",
    "                transcript += audio_dict['transcript']\n",
    "                print(audio_dict['transcript'], end=\"\", flush=True)\n",
    "\n",
    "print(\"\\n\\nProcessing audio...\")\n",
    "\n",
    "# Combine all audio chunks\n",
    "if audio_chunks:\n",
    "    audio_data = b\"\".join(audio_chunks)\n",
    "    \n",
    "    # Save as WAV file\n",
    "    try:\n",
    "        with wave.open(\"output.wav\", \"wb\") as wav_file:\n",
    "            wav_file.setnchannels(1)  # Mono\n",
    "            wav_file.setsampwidth(2)  # 16-bit\n",
    "            wav_file.setframerate(24000)  # 24kHz\n",
    "            wav_file.writeframes(audio_data)\n",
    "        \n",
    "        print(f\"Audio saved to output.wav ({len(audio_data)} bytes)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving WAV file: {e}\")\n",
    "        \n",
    "        # Save as raw PCM if WAV fails\n",
    "        with open(\"output.pcm\", \"wb\") as f:\n",
    "            f.write(audio_data)\n",
    "        print(f\"Saved as raw PCM: output.pcm ({len(audio_data)} bytes)\")\n",
    "else:\n",
    "    print(\"No audio data received\")\n",
    "\n",
    "if audio_id:\n",
    "    print(f\"\\nAudio ID: {audio_id}\")\n",
    "\n",
    "if transcript:\n",
    "    print(f\"\\nFull transcript: {transcript}\")\n",
    "\n",
    "if text_response:\n",
    "    print(f\"\\nText response: {text_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb36a868-7d9b-4c02-8add-6e1a1edcf335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T08:07:13.305632Z",
     "iopub.status.busy": "2026-02-04T08:07:13.305393Z",
     "iopub.status.idle": "2026-02-04T08:07:13.309134Z",
     "shell.execute_reply": "2026-02-04T08:07:13.308550Z",
     "shell.execute_reply.started": "2026-02-04T08:07:13.305613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to output.wav\n",
      "\n",
      "Text response: \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "import wave\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY\n",
    ")\n",
    "\n",
    "def text_to_speech(text, output_file=\"output.wav\", voice=\"alloy\"):\n",
    "    \"\"\"Convert text to speech and save as WAV file\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-4o-audio-preview\",\n",
    "        modalities=[\"text\", \"audio\"],\n",
    "        stream=True,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "        audio={\n",
    "            \"voice\": voice,\n",
    "            \"format\": \"pcm16\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    audio_chunks = []\n",
    "    transcript = \"\"\n",
    "    \n",
    "    print(\"Processing...\")\n",
    "    \n",
    "    for chunk in response:\n",
    "        if hasattr(chunk.choices[0].delta, 'audio') and chunk.choices[0].delta.audio:\n",
    "            audio_dict = chunk.choices[0].delta.audio\n",
    "            \n",
    "            if isinstance(audio_dict, dict):\n",
    "                if 'data' in audio_dict and audio_dict['data']:\n",
    "                    decoded_audio = base64.b64decode(audio_dict['data'])\n",
    "                    audio_chunks.append(decoded_audio)\n",
    "                \n",
    "                if 'transcript' in audio_dict and audio_dict['transcript']:\n",
    "                    transcript += audio_dict['transcript']\n",
    "                    print(audio_dict['transcript'], end=\"\", flush=True)\n",
    "    \n",
    "    if audio_chunks:\n",
    "        audio_data = b\"\".join(audio_chunks)\n",
    "        \n",
    "        with wave.open(output_file, \"wb\") as wav_file:\n",
    "            wav_file.setnchannels(1)\n",
    "            wav_file.setsampwidth(2)\n",
    "            wav_file.setframerate(24000)\n",
    "            wav_file.writeframes(audio_data)\n",
    "        \n",
    "        print(f\"\\n\\nAudio saved to {output_file} ({len(audio_data)} bytes)\")\n",
    "        return output_file\n",
    "    else:\n",
    "        print(\"\\nNo audio data received\")\n",
    "        return None\n",
    "\n",
    "# Usage\n",
    "text_to_speech(\"Hello, how are you?\")\n",
    "\n",
    "# Different voice\n",
    "text_to_speech(\"This is a test message\", output_file=\"test.wav\", voice=\"nova\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d90b0961-0591-4694-a663-facd4bdfde0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-04T08:07:34.223884Z",
     "iopub.status.busy": "2026-02-04T08:07:34.223630Z",
     "iopub.status.idle": "2026-02-04T08:07:34.227546Z",
     "shell.execute_reply": "2026-02-04T08:07:34.226860Z",
     "shell.execute_reply.started": "2026-02-04T08:07:34.223868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19162046-80ac-477d-a93e-24be856d07bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
